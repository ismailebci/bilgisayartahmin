import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.impute import SimpleImputer
import xgboost as xgb
from catboost import CatBoostRegressor

# Veri setini yÃ¼kleme
data = pd.read_csv('masaustu_data_kaggle.csv')

# Eksik verileri doldurma
data.ffill(inplace=True)

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve baÄŸÄ±mlÄ± deÄŸiÅŸken (y)
X = data.drop(columns=['Fiyat'])  # 'Fiyat' sÃ¼tunu hedef deÄŸiÅŸken olarak kabul edildi
y = data['Fiyat']

# Kategorik ve sayÄ±sal sÃ¼tunlarÄ± belirleme (X'e gÃ¶re)
categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns

# Veriyi eÄŸitim ve test kÃ¼melerine ayÄ±rma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Veri Ã¶n iÅŸleme adÄ±mlarÄ±
preprocessor = ColumnTransformer(
    transformers=[
        ('num', SimpleImputer(strategy='mean'), numerical_cols),  # Eksik sayÄ±sal deÄŸerleri ortalama ile doldur
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # Kategorik deÄŸiÅŸkenleri one-hot encode et
    ])

# Model eÄŸitimi ve deÄŸerlendirme iÃ§in fonksiyon
def train_and_evaluate(model, params, X_train, y_train, X_test, y_test):
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    grid_search = GridSearchCV(pipeline, params, cv=3, scoring='r2', n_jobs=-1, verbose=1, error_score='raise')
    grid_search.fit(X_train, y_train)
    y_pred = grid_search.best_estimator_.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    return mae, r2, grid_search.best_estimator_, grid_search.best_params_

# XGBoost Modeli
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
xgb_params = {
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__max_depth': [3, 5, 7],
    'model__n_estimators': [100, 200, 300]
}
mae_xgb, r2_xgb, xgb_best_estimator, xgb_best_params = train_and_evaluate(xgb_model, xgb_params, X_train, y_train, X_test, y_test)

# Random Forest Modeli (Ä°yileÅŸtirilmiÅŸ)
rf_model = RandomForestRegressor(random_state=42)
rf_params = {
    'model__n_estimators': [100, 200, 300],
    'model__max_depth': [5, 10, 15],  # max_depth sÄ±nÄ±rlandÄ±rÄ±ldÄ±
    'model__min_samples_split': [2, 5, 10],
    'model__min_samples_leaf': [1, 2, 4]  # min_samples_leaf eklendi
}
mae_rf, r2_rf, rf_best_estimator, rf_best_params = train_and_evaluate(rf_model, rf_params, X_train, y_train, X_test, y_test)

# Gradient Boosting Modeli (Ä°yileÅŸtirilmiÅŸ)
gb_model = GradientBoostingRegressor(random_state=42)
gb_params = {
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__n_estimators': [100, 200, 300],
    'model__max_depth': [3, 5, 7],
    'model__min_samples_split': [2, 5, 10],  # min_samples_split eklendi
    'model__min_samples_leaf': [1, 2, 4]  # min_samples_leaf eklendi
}
mae_gb, r2_gb, gb_best_estimator, gb_best_params = train_and_evaluate(gb_model, gb_params, X_train, y_train, X_test, y_test)

# CatBoost Modeli
cat_model = CatBoostRegressor(random_state=42, verbose=0)
cat_params = {
    'model__learning_rate': [0.01, 0.1, 0.2],
    'model__max_depth': [3, 5, 7],
    'model__n_estimators': [100, 200, 300]
}
mae_cat, r2_cat, cat_best_estimator, cat_best_params = train_and_evaluate(cat_model, cat_params, X_train, y_train, X_test, y_test)

# Model KarÅŸÄ±laÅŸtÄ±rmasÄ±
print("\nğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:")
print(f"XGBoost RÂ²: {r2_xgb:.4f}, MAE: {mae_xgb:.2f}")
print(f"Random Forest RÂ²: {r2_rf:.4f}, MAE: {mae_rf:.2f}")
print(f"Gradient Boosting RÂ²: {r2_gb:.4f}, MAE: {mae_gb:.2f}")
print(f"CatBoost RÂ²: {r2_cat:.4f}, MAE: {mae_cat:.2f}")

# Yeni bilgisayarÄ±n Ã¶zelliklerini tanÄ±mlayÄ±n
new_computer = {
    'Marka': ['HP'],  # Ã–rnek marka
    'Ä°ÅŸlemci Tipi': ['Intel Core i5'],  # Ã–rnek iÅŸlemci
    'SSD Kapasitesi': ['512 GB'],  # 3 TB SSD
    'Ram (Sistem BelleÄŸi)': ['8 GB'],  # 64 GB RAM
    'Ekran KartÄ±': ['NVIDIA GeForce RTX 3050'],  # Ã–rnek ekran kartÄ±
    'Kapasite': ['512 GB'],  # 3 TB depolama
    'Ä°ÅŸletim Sistemi': ['Windows'],  # Ã–rnek iÅŸletim sistemi
    'Ekran KartÄ± Bellek Tipi': ['GDDR5'],  # Ã–rnek bellek tipi
    'Ekran KartÄ± Tipi': ['Dedicated'],  # Ã–rnek ekran kartÄ± tipi
    'Garanti Tipi': ['Resmi Garanti'],  # Ã–rnek garanti tipi
    'Ram (Sistem BelleÄŸi) Tipi': ['DDR4'],  # Ã–rnek RAM tipi
    'Ä°ÅŸlemci Ã‡ekirdek SayÄ±sÄ±': ['16'],  # 16 Ã§ekirdek
    'Ä°ÅŸlemci Nesli': ['11. Nesil'],  # Ã–rnek iÅŸlemci nesli
    'Ä°ÅŸlemci Modeli': ['i5-11500H'],  # Ã–rnek iÅŸlemci modeli
    'Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k': ['1920x1080'],  # 4K Ã§Ã¶zÃ¼nÃ¼rlÃ¼k
    'Power Supply': ['800W'],  # 800W gÃ¼Ã§ kaynaÄŸÄ±
    'KullanÄ±m AmacÄ±': ['Oyun ve Ä°ÅŸ'],  # Ã–rnek kullanÄ±m amacÄ±
    'Ekran KartÄ± HafÄ±zasÄ±': ['4 GB'],  # 24 GB ekran kartÄ± hafÄ±zasÄ±
    'Temel Ä°ÅŸlemci HÄ±zÄ± (GHz)': ['3.5 GHz'],  # 3.5 GHz temel hÄ±z
    'BaÄŸlantÄ±lar': ['Wi-Fi 6, Bluetooth 5.2'],  # Ã–rnek baÄŸlantÄ±lar
    'Cihaz AÄŸÄ±rlÄ±ÄŸÄ±': ['2.5 kg'],  # 2.5 kg aÄŸÄ±rlÄ±k
    'Ekran Boyutu': ['16 inÃ§'],  # 16 inÃ§ ekran
    'Ä°ÅŸlemci FrekansÄ±': ['3.2 GHz'],  # 5.8 GHz maksimum frekans
    'Ekran Yenileme HÄ±zÄ±': ['144 Hz'],  # 120 Hz yenileme hÄ±zÄ±
    'Panel Tipi': ['IPS'],  # IPS panel
    'MenÅŸei': ['ABD'],  # Ã–rnek menÅŸei
    'ArttÄ±rÄ±labilir Azami Bellek': ['128 GB']  # 128 GB'a kadar bellek
}

# Yeni bilgisayarÄ± bir DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
new_computer_df = pd.DataFrame(new_computer)

# Eksik sÃ¼tunlarÄ± kontrol edin ve varsayÄ±lan deÄŸerlerle doldurun
for col in X_train.columns:
    if col not in new_computer_df.columns:
        new_computer_df[col] = 'Unknown'  # VarsayÄ±lan deÄŸer

# SÃ¼tun sÄ±ralamasÄ±nÄ± eÄŸitim verisiyle aynÄ± yapÄ±n
new_computer_df = new_computer_df[X_train.columns]

# Tahmin yapma
y_pred_xgb_new = xgb_best_estimator.predict(new_computer_df)
y_pred_rf_new = rf_best_estimator.predict(new_computer_df)
y_pred_gb_new = gb_best_estimator.predict(new_computer_df)
y_pred_cat_new = cat_best_estimator.predict(new_computer_df)

# SonuÃ§larÄ± yazdÄ±rÄ±n
print("\nğŸ“Š Yeni BilgisayarÄ±n Tahmin FiyatlarÄ±:")
print(f"XGBoost Tahmini Fiyat: {y_pred_xgb_new[0]:.2f} TL")
print(f"Random Forest Tahmini Fiyat: {y_pred_rf_new[0]:.2f} TL")
print(f"Gradient Boosting Tahmini Fiyat: {y_pred_gb_new[0]:.2f} TL")
print(f"CatBoost Tahmini Fiyat: {y_pred_cat_new[0]:.2f} TL")

# Ensemble Tahmini (AÄŸÄ±rlÄ±klÄ± Ortalama)
weights = [r2_xgb, r2_rf, r2_gb, r2_cat]  # RÂ² skorlarÄ±na gÃ¶re aÄŸÄ±rlÄ±k
weights = np.array(weights) / np.sum(weights)  # Normalize et
y_pred_ensemble = (y_pred_xgb_new * weights[0] + y_pred_rf_new * weights[1] + y_pred_gb_new * weights[2] + y_pred_cat_new * weights[3])
print(f"\nğŸ“Š Ensemble Tahmini Fiyat: {y_pred_ensemble[0]:.2f} TL")
